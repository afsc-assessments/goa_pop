# notes ----
# code for 2023 goa pop data queries and such 
# pete.hulson@noaa.gov
# maia.kapur@noaa.gov
# ben.williams@noaa.gov

# load ----

# devtools::unload("afscdata")
# devtools::unload("afscassess")

devtools::install_github("afsc-assessments/afscdata", force = TRUE)
devtools::install_github("BenWilliams-NOAA/afscassess@devph", force = TRUE)
# devtools::install_github("BenWilliams-NOAA/afscassess", force = TRUE)

# library(afscdata)
library(afscassess)

# previous accepted model
# this is more for an example since the previous assessment was not in the afscdata framework
# accepted_model(base_year=2021, base_model="model_20_1", year=2023)

# globals ----
year = 2023
rec_age = 2
plus_age = 25
lengths = 16:45
TAC = c(31238, 36177, 38268) # previous 3 years
species = "POP"
admb_home = "C:/ADMB-13.0" # I use this because I have multiple admb versions


afscassess::sp_switch(species)
# setup folder structure - only run this once
# afscdata::setup_folders(year)
# setup .tpl files
# afscassess::setup_tpl(year)

# query data ----
## you must be on the VPN for this to work
afscdata::goa_pop(year)

# get data files together (dat and ctl) ----

# weight-at-age
# note from ben on these admb called functions: !!! I'm having trouble running this function via R2admb so stepped out and ran it command line, works fine if I compile it command line and then use the R2admb run function, maybe I'll pass the .exe instead of rebuilding the .tpl each year?
afscassess::weight_at_age(year = year,
                          admb_home = admb_home,
                          rec_age = rec_age,
                          area = "goa")

# fishery catch
afscassess::clean_catch(year = year, 
                        species = species, 
                        TAC = TAC)

# bottom trawl survey biomass
afscassess::bts_biomass(year = year, 
                        rmv_yrs = c(1984, 1987))

# fishery age comp
# base case (currently used)
afscassess::fish_age_comp(year = year,
                          exp_meth = 'marg_len',
                          rec_age = rec_age, 
                          plus_age = plus_age,
                          lenbins = lengths,
                          rmv_yrs = c(1987, 1989))
# expanded comps (expanded in years with obs catch data)
# afscassess::fish_age_comp(year = year,
#                           exp_meth = 'exp_len',
#                           rec_age = rec_age, 
#                           plus_age = plus_age,
#                           lenbins = lengths,
#                           rmv_yrs = c(1987, 1989),
#                           id = "exp")

# bottom trawl survey age comp
afscassess::bts_age_comp(year = year,
                         area = "goa",
                         rec_age = rec_age,
                         plus_age = plus_age,
                         rmv_yrs = c(1984,1987))

# fishery size comp
afscassess::fish_length_comp_pop(year = year,
                                 rec_age = rec_age,
                                 lenbins = lengths,
                                 rmv_yrs = c(1988, 1993, 1994, 2003, 2007, 2009, 2011, 2013, 2015, 2017, 2019, 2021, 2022, 2023))

# bottom trawl survey size comp
afscassess::bts_length_comp(year = year,
                            area = "goa",
                            lenbins = lengths)

# 60s size-age matrix
afscassess::size_at_age_pop_60(year = year,
                               rec_age = rec_age,
                               lenbins = lengths)

# current size-age matrix
afscassess::size_at_age(year = year,
                        admb_home = admb_home,
                        rec_age = rec_age,
                        lenbins = lengths)

# ageing error matrix
afscassess::age_error(year = year, 
                      reader_tester = "reader_tester.csv", 
                      admb_home = admb_home, 
                      species = species, 
                      rec_age = rec_age, 
                      plus_age = plus_age)

# concatenate dat file, for now writing it to output folder in data
afscassess::concat_dat_pop(year = year,
                           species = species,
                           area = "goa",
                           folder = "data/output",
                           dat_name = "goa_pop",
                           rec_age = rec_age,
                           plus_age = plus_age,
                           spawn_mo = 5)

# write ctl file, for now writing it to output folder in data
afscassess::write_ctl_pop(year = year,
                          base_mdl_fldr = '2020.1-2021',
                          mdl_name = "Model_1",
                          ctl_name = "goa_pop",
                          dat_name = "goa_pop",
                          folder = "data/output")

# run base model ----
# write dat and ctl files to base model folder
afscassess::concat_dat_pop(year = year,
                           species = species,
                           area = "goa",
                           folder = "mgmt/2020.1-2023",
                           dat_name = "goa_pop",
                           rec_age = rec_age,
                           plus_age = plus_age,
                           spawn_mo = 5)

afscassess::write_ctl_pop(year = year,
                          base_mdl_fldr = '2020.1-2021',
                          mdl_name = "Model_1",
                          ctl_name = "goa_pop",
                          dat_name = "goa_pop",
                          folder = "mgmt/2020.1-2023")

# run model
setwd(here::here(year, "mgmt", "2020.1-2023"))

R2admb::run_admb("model_20_1", verbose = TRUE)


process_results_pop(year = year,
                    model_dir = here::here(year, "mgmt", "2020.1-2023"), 
                    rec_age = rec_age,
                    plus_age = plus_age, 
                    MCMC = FALSE)
  

#' @param year  assessment year
#' @param model_dir  full path of model being evaluated  
#' @param MCMC = logical, does this run include MCMC evaluations to be processed?
#' @param no_mcmc = number of mcmc runs
#' @param rec_age recruitment age
#' @param plus_age plus age group 
#' @param mcsave the number of mcmcs saved 
#' @param ... future functions

process_results_pop <- function(year=2023, model_dir, 
                                rec_age=2, plus_age=25, MCMC=FALSE, no_mcmc = 100000, mcsave=100, ...){
  
  # setup
  
  if (!dir.exists(paste0(model_dir, "/processed"))){
    dir.create(paste0(model_dir, "/processed"), recursive=TRUE)
  }
  
  if (!dir.exists(paste0(model_dir, "/figs"))){
    dir.create(paste0(model_dir, "/figs"), recursive=TRUE)
  }
  if (!dir.exists(paste0(model_dir, "/tables"))){
    dir.create(paste0(model_dir, "/tables"), recursive=TRUE)
  }
  
  
  # helper functions
  rep_item <- function(name){
    t <- strsplit(REP[grep(name, REP)]," ")
    t <- subset(t[[1]], t[[1]]!="")
    if(t[[1]][1] == "TWL"){
      as.numeric(t[3:length(t)])
    } else {
      as.numeric(t[2:length(t)])
    }
  }
  
  
  # read in report and ctl files
  dats <- list.files(model_dir, full.names = TRUE)
  DAT <- readLines(dats[grepl("*.dat",dats) & !grepl('proj',dats)])
  REP <- readLines(list.files(model_dir, pattern="*.rep", full.names = TRUE)) 
  modname <- gsub(".rep","",basename(list.files(model_dir, pattern="*.rep", full.names = TRUE))) ## strip model name from rep file
  CTL <- readLines(list.files(model_dir, pattern="*.ctl", full.names = TRUE)) 
  STD <- read.delim(list.files(model_dir, pattern="*.std", full.names = TRUE), sep="", header = TRUE) 
  
  
  # clean rep file
  suppressWarnings(data.frame(year = unlist(base::strsplit(REP[grep("Year", REP)[1]]," "))) %>%
                     tidytable::mutate.(year = as.numeric(year)) %>%
                     tidytable::drop_na.() %>%
                     tidytable::pull.(year)) -> yrs
  
  suppressWarnings(data.frame(age = unlist(base::strsplit(REP[grep("Age", REP)[1]]," "))) %>%
                     tidytable::mutate.(age = as.numeric(age)) %>%
                     tidytable::drop_na.() %>%
                     tidytable::pull.(age)) -> ages
  
  styr_rec <- yrs[1] - length(ages) + rec_age
  
  suppressWarnings(as.data.frame(cbind(yrs = yrs, ages = ages, styr_rec = styr_rec)) %>%
                     tidytable::mutate.(ages = replace(ages, duplicated(ages), NA),
                                        styr_rec = replace(styr_rec, duplicated(styr_rec), NA))) %>%
    write.csv(paste0(model_dir, "/processed/ages_yrs.csv"), row.names = FALSE)
  
  ## pull out likelihoods ----
  ## this function extracts & binds them rowwise
  do.call(rbind, 
          lapply(unlist(base::strsplit(REP[grep('Likelihood|Priors|Penalty|Objective', REP)][2:19],"\n")), 
                 FUN = function(x){
                   tmpl <- unlist(strsplit(x," "))
                   tempr <- matrix(c(tmpl[1], tmpl[2], paste0(tmpl[3:length(tmpl)], collapse = ' ')), ncol = 3)
                   return(tempr)
                 })) %>% 
    data.frame() %>%
    tidytable::mutate(value = as.numeric(X2),
                      weight = as.numeric(X1)) %>%
    tidytable::select(weight, value , variable = X3) %>% 
    tidytable::mutate(model = basename(model_dir),
                      weight = ifelse(is.na(weight) == TRUE, 1, weight)) -> likes
  write.csv(likes, paste0(model_dir, "/processed/likelihoods.csv"), row.names = FALSE)
  
  
  # MCMC parameters ----
  if(MCMC){
    mceval <- read.delim(list.files(model_dir, pattern="*evalout.prj", full.names = TRUE), sep="", header = FALSE) 
    PSV <- file(paste0(model_dir,"/",modname,".psv"), "rb")
    
    npar = readBin(PSV, what = integer(), n=1)
    mcmcs = readBin(PSV, what = numeric(), n = (npar * no_mcmc / mcsave))
    close(PSV)
    mcmc_params = matrix(mcmcs, byrow=TRUE, ncol=npar)
    # thin the string
    mcmc_params = mcmc_params[501:nrow(mcmc_params),]
    colnames(mcmc_params) = STD$name[1:ncol(mcmc_params)]
    write.csv(mcmc_params,paste0(model_dir, "/processed/mcmc.csv"), row.names = FALSE)
    
    # mceval phase output ----
    
    #Curry's Change
    mceval = mceval[501:nrow(mceval),]
    
    #Length colnames = 286
    # columns mcmc_other = 271
    
    #1-8: Through objective function value
    
    colnames(mceval) = c("sigr", "q_srv1", "q_srv2", "F40", "natmort", "spawn_biom_proj",
                         "ABC", "obj_fun",
                         paste0("tot_biom_", yrs),
                         paste0("log_rec_dev_", seq(styr_rec, yrs[length(yrs)])),
                         paste0("spawn_biom_", yrs),
                         "log_mean_rec",
                         paste0("spawn_biom_proj_", max(yrs) + 1:15),
                         paste0("pred_catch_proj_", max(yrs) + 1:15),
                         paste0("rec_proj_", max(yrs) + 1:10),
                         paste0("tot_biom_proj_", max(yrs)))
    write.csv(mceval, paste0(model_dir, "/processed/mceval.csv"), row.names = FALSE)
    
  } ## end if MCMC == T
  
  # catch data ----
  pred = base::strsplit(REP[grep("Pred_Catch", REP)], " ")
  r1 = which(pred[[1]] == "Pred_Catch")
  r2 = which(pred[[1]] == "Pred_catch_later")
  r3 = which(pred[[1]] == "")
  pred = as.numeric(pred[[1]][-c(r1, r2, r3)])
  
  obs = base::strsplit(REP[grep("Obs_Catch", REP)], " ")
  r1 = which(obs[[1]] == "Obs_Catch")
  r2 = which(obs[[1]] == "Obs_Catch_Later")
  r3 = which(obs[[1]] == "")
  obs = as.numeric(obs[[1]][-c(r1, r2, r3)])
  
  data.frame(year = yrs, obs = obs, pred = pred) -> catch
  write.csv(catch, paste0(model_dir, "/processed/catch.csv"), row.names = FALSE)
  
  # survey data ----
  syr = REP[grep("Survey Biomass",REP)[1]:(grep("Survey Biomass",REP)[2]-2)][2]
  syr = base::strsplit(syr," ")
  syr = subset(syr[[1]], syr[[1]]!="")
  syr = as.numeric(syr[2:length(syr)])
  
  obs = REP[grep("Survey Biomass",REP)[1]:(grep("Survey Biomass",REP)[2]-2)][4]
  obs = base::strsplit(obs," ")
  obs = subset(obs[[1]], obs[[1]]!="")
  obs = as.numeric(obs[2:length(obs)])
  
  se = REP[grep("Survey Biomass",REP)[1]:(grep("Survey Biomass",REP)[2]-2)][5]
  se = base::strsplit(se," ")
  se = subset(se[[1]], se[[1]]!="")
  se = as.numeric(se[2:length(se)])
  
  pred = REP[grep("Survey Biomass",REP)[1]:(grep("Survey Biomass",REP)[2]-2)][3]
  pred = base::strsplit(pred," ")
  pred = subset(pred[[1]], pred[[1]]!="")
  pred = as.numeric(pred[2:length(pred)])
  
  
  data.frame(year = syr, biomass = obs, pred = pred, se = se) %>%
    tidytable::mutate.(lci = biomass - 1.96 * se,
                       uci = biomass + 1.96 * se,
                       lci = ifelse(lci < 0, 0 ,lci)) -> srv
  write.csv(srv, paste0(model_dir, "/processed/survey.csv"), row.names = FALSE)
  
  # recruitment ----
  N = REP[grep("Numbers", REP):(grep("Obs_P_fish_age", REP)-2)]
  t = NA
  for(i in 1:length(yrs)){
    ts = as.numeric(base::strsplit(N[i+1]," ")[[1]][3])
    t = c(t, ts)
  }
  pred_rec = t[!is.na(t)]
  
  # biomass & F & recruits ----
  data.frame(year = yrs,
             tot_biom = afscassess::rep_item("Tot_biom"),
             sp_biom = afscassess::rep_item("SpBiom"),
             F = afscassess::rep_item("Fully_selected_F"),
             recruits = pred_rec) -> bio_rec_f
  write.csv(bio_rec_f, paste0(model_dir, "/processed/bio_rec_f.csv"), row.names = FALSE)
  
  # selectivity ----
  data.frame(age = ages,
             fish1 = afscassess::rep_item("Fishery_Selectivity_1967-1976"),
             fish2 = afscassess::rep_item("Fishery_Selectivity_1977-1995"),
             fish3 = afscassess::rep_item("Fishery_Selectivity_1996-2006"),
             fish4 = afscassess::rep_item(paste0("Fishery_Selectivity_2007-", year)),
             srv1 = afscassess::rep_item("Trawl_Survey_Selectivity")) -> selex
  write.csv(selex, paste0(model_dir, "/processed/selex.csv"), row.names = FALSE)
  
  # weight-at-age, maturity ----
  data.frame(age = ages,
             srv1 = afscassess::rep_item("Weight"),
             maturity = afscassess::rep_item("Maturity")) -> waa_mat
  write.csv(waa_mat, paste0(model_dir, "/processed/selex.csv"), row.names = FALSE)
  
  # number of paramters ----
  
  data.frame(num_param = as.numeric(REP[(grep("Number parameters estimated",REP)+1)]))
  
  
  # projected biomass ----
  
  data.frame(B40 = STD$value[which(STD$name=="B40")],
             B35 = as.numeric(REP[(grep("B_35",REP)+1):(grep("F_40",REP)[1]-1)]),
             yld_rat = as.numeric(unlist(base::strsplit(CTL[grep("yieldratio", CTL)], " "))[1])) 
  
  # management quants (ABC, OFL, yield ratio, B40 & B35----
  
  data.frame(B40 = STD$value[which(STD$name=="B40")],
             B35 = as.numeric(REP[(grep("B_35",REP)+1):(grep("F_40",REP)[1]-1)]),
             yld_rat = as.numeric(unlist(base::strsplit(CTL[grep("yieldratio", CTL)], " "))[1])) %>%
    write.csv(paste0(model_dir, "/processed/b35_b40_yld.csv"), row.names = FALSE)
  
  # size comps ----
  size_bins <- as.numeric(strsplit(DAT[grep('len_bin_labels', DAT)+1]," ")[[1]])
  
  cat('processed results for', basename(model_dir),'\n')
  
  
  
  
  t <- list(yrs = yrs, 
            ages = ages,
            styr_rec = styr_rec,
            likes = likes,
            catch = catch,
            srv = srv)
  
  
  
  
  
  
  #! this will need a switch for multiple surveys
  
  #   obs = REP[grep("Obs_P_fish_age",REP):(grep("Pred_P_fish_age",REP)-2)]
  #   pred = REP[grep("Pred_P_fish_age",REP):(grep("Obs_P_fish_size",REP)-2)]
  
  #   obs_l = REP[grep("Obs_P_fish_size",REP):(grep("Pred_P_fish_size",REP)-2)]
  #   pred_l = REP[grep("Pred_P_fish_size",REP):(grep("Obs_P_srv1_age",REP)-2)]
  
  #   s_obs = REP[grep("Obs_P_srv1_age",REP):(grep("Pred_P_srv1_age",REP)-2)]
  #   s_pred = REP[grep("Pred_P_srv1_age",REP):(grep("Obs_P_srv1_size",REP)-2)]
  
  #   s_obs_l = REP[grep("Obs_P_srv1_size",REP):(grep("Pred_P_srv1_size",REP)-2)]
  
  #   afscassess::purrit(obs, pred, rec_age, plus_age, comp = "age", lenbins = size_bins) %>%
  #     write.csv(paste0(model_dir, "/processed/fac.csv"))
  
  #   afscassess::purrit(obs_l, pred_l, rec_age, plus_age, comp = "length", lenbins = size_bins) %>%
  #     write.csv(paste0(model_dir, "/processed/fsc.csv"))
  
  #   afscassess::purrit(s_obs, s_pred, rec_age, plus_age, comp = "age", lenbins = size_bins) %>%
  #     write.csv(paste0(model_dir, "/processed/sac.csv"))
  
  #   afscassess::purrit(s_obs_l, pred = NULL, rec_age, plus_age, comp = "length", lenbins = size_bins) %>%
  #     write.csv(paste0(model_dir, "/processed/ssc.csv"))
  
}

















